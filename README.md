
# üîç Web-Scraped RAG (Retrieval-Augmented Generation) Application

This project is a fullstack **Retrieval-Augmented Generation (RAG)** system that lets users ask questions about the content scraped from a given website. It combines web scraping, semantic search, and large language models to generate relevant answers with real-time data ingestion.

---

## ‚ú® Features

- üï∏Ô∏è **Web Scraping:** Extracts content from webpages using BeautifulSoup.
- üß† **Semantic Embedding:** Embeds text using Hugging Face Transformers.
- üîç **FAISS Vector Store:** Efficient similarity search over embedded chunks.
- ü§ñ **LLM Q&A with LangChain:** Retrieves relevant content and uses LLMs to generate responses.
- üñ•Ô∏è **React Frontend:** Clean user interface to ask questions and display answers.
- üê≥ **Dockerized:** Fully containerized using Docker with separate services for frontend and backend.

---

## üß∞ Tech Stack

| Layer        | Tools/Libraries                          |
|--------------|-------------------------------------------|
| **Backend**  | FastAPI, BeautifulSoup, FAISS, LangChain |
| **Frontend** | React.js, Axios                          |
| **Embedding**| Hugging Face Transformers                |
| **DevOps**   | Docker, Docker Compose                   |

---

## üìÇ Folder Structure

```

rag-app/
‚îÇ
‚îú‚îÄ‚îÄ backend/              # FastAPI app for ingestion and Q\&A
‚îÇ   ‚îú‚îÄ‚îÄ app.py            # Main API server
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py         # Web scraper and embedding logic
‚îÇ   ‚îú‚îÄ‚îÄ vector\_store.py   # FAISS vector DB logic
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt  # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ frontend/             # React application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml    # Runs frontend and backend containers
‚îú‚îÄ‚îÄ Dockerfile            # Multi-stage Docker build
‚îî‚îÄ‚îÄ README.md             # Project documentation

````

---

## ‚öôÔ∏è How It Works

1. **Web Ingestion:** 
   - `ingest.py` scrapes the webpage and chunks its content.
   - Each chunk is embedded and stored in a FAISS index.

2. **Question Answering:**
   - The user asks a question via the React UI.
   - The backend retrieves similar content chunks from FAISS.
   - LangChain and a local LLM generate a response based on context.

---

## üöÄ Getting Started

### 1. Clone the Repository


git clone https://github.com/yourusername/rag-app.git
cd rag-app
````

### 2. Build and Run with Docker


docker compose up --build
```

* Frontend: [http://localhost:3000](http://localhost:3000)
* Backend API: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üìù Future Improvements

* Add authentication
* Support for PDF/CSV ingestion
* Deploy to cloud (Render, Railway, etc.)
* Streamlit interface (optional)

---

## üìú License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## üôå Acknowledgements

* [Hugging Face Transformers](https://huggingface.co/)
* [LangChain](https://github.com/langchain-ai/langchain)
* [FAISS](https://github.com/facebookresearch/faiss)

---

> Built with ‚ù§Ô∏è using Python, React, and LLMs.

```

---

